{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# HW3\n",
    "\n",
    "By Group C"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Jupyter environment detected. Enabling Open3D WebVisualizer.\n",
      "[Open3D INFO] WebRTC GUI backend enabled.\n",
      "[Open3D INFO] WebRTCWindowSystem: HTTP handshake server disabled.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO - 2023-06-13 12:36:27,962 - _logger - Log opened: Tue Jun 13 10:36:27 2023 UTC\n",
      "INFO - 2023-06-13 12:36:27,977 - topics - topicmanager initialized\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.spatial.transform import Rotation\n",
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "import pyrosbag as prb\n",
    "from rosbags.highlevel import AnyReader\n",
    "import os\n",
    "from pathlib import Path\n",
    "import rosbag\n",
    "from cv_bridge import CvBridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "!source /opt/ros/noetic/setup.bash"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!pip install bagpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read source point cloud\n",
    "pcd_source = o3d.io.read_point_cloud('assets/models/oats/texturedMesh_alligned_vertex_color.ply')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "voxel_size = 0.01\n",
    "pcd_source = pcd_source.voxel_down_sample(voxel_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "o3d.visualization.draw_geometries([pcd_source])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 2\n",
    "### Task 2.1 and 2.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bag_file = \"bag_2022-05-11-14-37-56_0.bag\"\n",
    "bag_file = \"icp_tracking_oats.bag\"\n",
    "#camera_topic = \"/camera/141722071427/\"\n",
    "camera_topic = \"/camera/\"\n",
    "depth_info = \"aligned_depth_to_color/camera_info\"\n",
    "depth_raw = \"aligned_depth_to_color/image_raw\"\n",
    "color_info = \"color/camera_info\"\n",
    "color_raw = \"color/image_raw\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### For first fifty frames ###############################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "bag = rosbag.Bag(bag_file)\n",
    "frame = 0\n",
    "last_color = None\n",
    "last_depth = None\n",
    "pcd_list = []  # List to store PointCloud objects\n",
    "\n",
    "for topic, msg, ts in bag:\n",
    "    if frame >= 50:  # Break the loop after capturing 50 frames\n",
    "        break\n",
    "\n",
    "    if topic == camera_topic + color_raw:\n",
    "        image_data = msg\n",
    "        im = np.frombuffer(image_data.data, dtype=np.uint8).reshape(image_data.height, image_data.width, -1)\n",
    "        color = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "        color = np.flip(color, axis=1)\n",
    "        last_color = color\n",
    "    elif topic == camera_topic + depth_raw:\n",
    "        image_data = msg\n",
    "        im = np.frombuffer(image_data.data, dtype=np.uint16).reshape(image_data.height, image_data.width, -1)\n",
    "        depth = np.flip(im, axis=1)\n",
    "        last_depth = depth\n",
    "    elif topic == camera_topic + color_info:\n",
    "        last_msg = msg\n",
    "\n",
    "    if last_color is not None and last_depth is not None:\n",
    "        rgb_image = o3d.geometry.Image(last_color)\n",
    "        depth_image = o3d.geometry.Image(last_depth)\n",
    "\n",
    "        rgbd = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "            rgb_image, depth_image, convert_rgb_to_intensity=False)\n",
    "\n",
    "        fx = last_msg.K[0]\n",
    "        fy = last_msg.K[4]\n",
    "        cx = last_msg.K[2]\n",
    "        cy = last_msg.K[5]\n",
    "        width = last_msg.width\n",
    "        height = last_msg.height\n",
    "\n",
    "        camera_model = o3d.camera.PinholeCameraIntrinsic(width=width, height=height, fx=fx, fy=fy, cx=cx, cy=cy)\n",
    "\n",
    "        P_inv = np.array(last_msg.P).reshape((3, 4))\n",
    "        P_inv = np.vstack((P_inv, np.array([0, 0, 0, 1])))\n",
    "        P_inv = np.linalg.inv(P_inv)\n",
    "\n",
    "        pcd = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd, camera_model, P_inv)\n",
    "\n",
    "        pcd_list.append(pcd)\n",
    "        frame += 1\n",
    "\n",
    "bag.close()\n",
    "\n",
    "merged_pcd = o3d.geometry.PointCloud()\n",
    "for pcd in pcd_list:\n",
    "    merged_pcd += pcd\n",
    "\n",
    "o3d.visualization.draw_geometries([merged_pcd])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3.1 and 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import copy\n",
    "\n",
    "pcd = merged_pcd\n",
    "o3d.visualization.draw_geometries_with_editing([pcd])\n",
    "\n",
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp])\n",
    "    \n",
    "def pick_points(pcd):\n",
    "    print(\"\")\n",
    "    print(\"1) Please pick at least three correspondences using [shift + left click]\")\n",
    "    print(\"   Press [shift + right click] to undo point picking\")\n",
    "    print(\"2) After picking points, press 'Q' to close the window\")\n",
    "    vis = o3d.visualization.VisualizerWithEditing()\n",
    "    vis.create_window()\n",
    "    vis.add_geometry(pcd)\n",
    "    vis.run()  # User picks points\n",
    "    vis.destroy_window()\n",
    "    print(\"\")\n",
    "    return vis.get_picked_points()\n",
    "\n",
    "def demo_manual_registration(pcd_arg, oats_can_path):\n",
    "    print(\"Demo for manual ICP\")\n",
    "    \n",
    "    print(\"Generating first window (Textured Mesh Visualisation)\")\n",
    "    oats_can_pcd = o3d.io.read_point_cloud(oats_can_path)\n",
    "\n",
    "    print(\"Generating second window (Registration Result before Correspondences)\")\n",
    "    draw_registration_result(pcd_arg, oats_can_pcd, np.identity(4))\n",
    "\n",
    "    print(\"Generating third window (Picking points from Point Cloud of Textured Mesh)\")\n",
    "    picked_id_source = pick_points(pcd_arg)\n",
    "    \n",
    "    print(\"Generating fourth window (Picking points from oats can)\")\n",
    "    picked_id_target = pick_points(oats_can_pcd)\n",
    "\n",
    "    assert len(picked_id_source) >= 3 and len(picked_id_target) >= 3\n",
    "    assert len(picked_id_source) == len(picked_id_target)\n",
    "\n",
    "    corr = np.zeros((len(picked_id_source), 2))\n",
    "    corr[:, 0] = picked_id_source\n",
    "    corr[:, 1] = picked_id_target\n",
    "\n",
    "    print(\"Compute a rough transform using the correspondences given by the user\")\n",
    "    p2p = o3d.pipelines.registration.TransformationEstimationPointToPoint()\n",
    "    trans_init = p2p.compute_transformation(pcd_arg, oats_can_pcd, o3d.utility.Vector2iVector(corr))\n",
    "\n",
    "    print(\"Perform point-to-point ICP refinement\")\n",
    "    threshold = 0.03 \n",
    "    reg_p2p = o3d.pipelines.registration.registration_icp(\n",
    "        pcd_arg, oats_can_pcd, threshold, trans_init, p2p)\n",
    "\n",
    "    print(\"Generating fifth window (Registration Result After Correspondences)\")\n",
    "    draw_registration_result(pcd_arg, oats_can_pcd, reg_p2p.transformation)\n",
    "    print(\"\")\n",
    "    \n",
    "def draw_registration_result(source, target, transformation):\n",
    "    source_temp = copy.deepcopy(source)\n",
    "    target_temp = copy.deepcopy(target)\n",
    "    source_temp.paint_uniform_color([1, 0.706, 0])\n",
    "    target_temp.paint_uniform_color([0, 0.651, 0.929])\n",
    "    source_temp.transform(transformation)\n",
    "    o3d.visualization.draw_geometries([source_temp, target_temp])\n",
    "    \n",
    "demo_manual_registration(pcd, \"assets/models/oats/texturedMesh_alligned_vertex_color.ply\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Demo for manual ICP\n",
      "Generating first window (Textured Mesh Visualisation)\n",
      "Generating second window (Registration Result before Correspondences)\n",
      "Generating third window (Picking points from Point Cloud of Textured Mesh)\n",
      "\n",
      "1) Please pick at least three correspondences using [shift + left click]\n",
      "   Press [shift + right click] to undo point picking\n",
      "2) After picking points, press 'Q' to close the window\n",
      "[Open3D INFO] Picked point #136873 (1.3e+02, 58., 0.21) to add in queue.\n",
      "[Open3D INFO] Picked point #46073 (83., 26., 0.22) to add in queue.\n",
      "[Open3D INFO] Picked point #102690 (18., 41., 0.18) to add in queue.\n",
      "[Open3D INFO] Picked point #171622 (63., 70., 0.2) to add in queue.\n",
      "\n",
      "Generating fourth window (Picking points from oats can)\n",
      "\n",
      "1) Please pick at least three correspondences using [shift + left click]\n",
      "   Press [shift + right click] to undo point picking\n",
      "2) After picking points, press 'Q' to close the window\n",
      "[Open3D INFO] Picked point #64514 (-0.36, -0.28, -0.047) to add in queue.\n",
      "[Open3D INFO] Picked point #295104 (-0.49, 0.057, -0.7) to add in queue.\n",
      "[Open3D INFO] Picked point #24224 (-0.36, -0.31, -1.4) to add in queue.\n",
      "[Open3D INFO] Picked point #104631 (-0.045, -0.37, -0.74) to add in queue.\n",
      "\n",
      "Compute a rough transform using the correspondences given by the user\n",
      "Perform point-to-point ICP refinement\n",
      "Generating fifth window (Registration Result After Correspondences)\n",
      "\n",
      "Demo for manual ICP\n",
      "Generating first window (Textured Mesh Visualisation)\n",
      "Generating second window (Registration Result before Correspondences)\n",
      "Generating third window (Picking points from Point Cloud of Textured Mesh)\n",
      "\n",
      "1) Please pick at least three correspondences using [shift + left click]\n",
      "   Press [shift + right click] to undo point picking\n",
      "2) After picking points, press 'Q' to close the window\n",
      "[Open3D INFO] Picked point #139319 (1.3e+02, 59., 0.21) to add in queue.\n",
      "[Open3D INFO] Picked point #44912 (79., 26., 0.22) to add in queue.\n",
      "[Open3D INFO] Picked point #105666 (15., 42., 0.18) to add in queue.\n",
      "[Open3D INFO] Picked point #175425 (72., 73., 0.21) to add in queue.\n",
      "\n",
      "Generating fourth window (Picking points from oats can)\n",
      "\n",
      "1) Please pick at least three correspondences using [shift + left click]\n",
      "   Press [shift + right click] to undo point picking\n",
      "2) After picking points, press 'Q' to close the window\n",
      "[Open3D INFO] Picked point #21410 (-0.3, -0.32, -0.053) to add in queue.\n",
      "[Open3D INFO] Picked point #297937 (-0.5, 0.026, -0.72) to add in queue.\n",
      "[Open3D INFO] Picked point #93018 (-0.34, -0.32, -1.3) to add in queue.\n",
      "[Open3D INFO] Picked point #116760 (-0.018, -0.37, -0.65) to add in queue.\n",
      "\n",
      "Compute a rough transform using the correspondences given by the user\n",
      "Perform point-to-point ICP refinement\n",
      "Generating fifth window (Registration Result After Correspondences)\n"
     ]
    }
   ],
   "source": [
    "import open3d as o3d\n",
    "\n",
    "bag = rosbag.Bag(bag_file)\n",
    "frame = 0\n",
    "last_color = None\n",
    "last_depth = None\n",
    "pcd_list = []  \n",
    "\n",
    "for topic, msg, ts in bag:\n",
    "    if frame >= 50: \n",
    "        break\n",
    "\n",
    "    if topic == camera_topic + color_raw:\n",
    "\n",
    "        image_data = msg\n",
    "        im = np.frombuffer(image_data.data, dtype=np.uint8).reshape(image_data.height, image_data.width, -1)\n",
    "        color = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "        color = np.flip(color, axis=1)\n",
    "        last_color = color\n",
    "    elif topic == camera_topic + depth_raw:\n",
    "\n",
    "        image_data = msg\n",
    "        im = np.frombuffer(image_data.data, dtype=np.uint16).reshape(image_data.height, image_data.width, -1)\n",
    "\n",
    "        depth = np.flip(im, axis=1)\n",
    "        last_depth = depth\n",
    "    elif topic == camera_topic + color_info:\n",
    "        last_msg = msg\n",
    "\n",
    "    if last_color is not None and last_depth is not None:\n",
    "\n",
    "        rgb_image = o3d.geometry.Image(last_color)\n",
    "        depth_image = o3d.geometry.Image(last_depth)\n",
    "\n",
    "        rgbd = o3d.geometry.RGBDImage.create_from_color_and_depth(\n",
    "            rgb_image, depth_image, convert_rgb_to_intensity=False)\n",
    "\n",
    "\n",
    "        fx = last_msg.K[0]\n",
    "        fy = last_msg.K[4]\n",
    "        cx = last_msg.K[2]\n",
    "        cy = last_msg.K[5]\n",
    "        width = last_msg.width\n",
    "        height = last_msg.height\n",
    "\n",
    "        camera_model = o3d.camera.PinholeCameraIntrinsic(width=width, height=height, fx=fx, fy=fy, cx=cx, cy=cy)\n",
    "\n",
    "        P_inv = np.array(last_msg.P).reshape((3, 4))\n",
    "        P_inv = np.vstack((P_inv, np.array([0, 0, 0, 1])))\n",
    "        P_inv = np.linalg.inv(P_inv)\n",
    "\n",
    "\n",
    "        pcd = o3d.geometry.PointCloud.create_from_rgbd_image(rgbd, camera_model, P_inv)\n",
    "        demo_manual_registration(pcd, \"assets/models/oats/texturedMesh_alligned_vertex_color.ply\")\n",
    "\n",
    "#         # Append PointCloud to the list\n",
    "#         pcd_list.append(pcd)\n",
    "#         frame += 1\n",
    "\n",
    "bag.close()\n",
    "\n",
    "# # Merge the point clouds\n",
    "# merged_pcd = o3d.geometry.PointCloud()\n",
    "# for pcd in pcd_list:\n",
    "#     merged_pcd += pcd\n",
    "\n",
    "# # Visualize the merged point cloud\n",
    "# o3d.visualization.draw_geometries([merged_pcd])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
